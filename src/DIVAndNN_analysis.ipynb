{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# BlueCloud Zooplankton Demonstrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DIVAnd\n",
    "using DIVAndNN\n",
    "using Random\n",
    "using NCDatasets\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "push!(LOAD_PATH,@__DIR__)\n",
    "using BlueCloudPlankton\n",
    "using DataStructures\n",
    "using Printf\n",
    "using Dates\n",
    "using JSON\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed for random number generator and include grid information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234)\n",
    "include(\"grid.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data frome the continuous plankton recorder\n",
    "https://www.cprsurvey.org/services/the-continuous-plankton-recorder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "datafile = joinpath(datadir, \"data-cpr.csv\")\n",
    "maybedownload(\"https://dox.ulg.ac.be/index.php/s/ME3U5wPdPK8GRFu/download\",\n",
    "              datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the depth range of the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, columnnames = readdlm(datafile, ',', header=true);\n",
    "getcolumn(name) = data[:,findfirst(columnnames[:] .== name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# check the depth range of the data\n",
    "minimumDepthInMeters = getcolumn(\"minimumDepthInMeters\")\n",
    "maximumDepthInMeters = getcolumn(\"maximumDepthInMeters\")\n",
    "@show extrema(minimumDepthInMeters)\n",
    "@show extrema(maximumDepthInMeters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prepare following fields:\n",
    "* Temperature and salinity from SeaDataCloud\n",
    "* Nitrate, silicate and phosphate from World Ocean Atlas 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TS = [\n",
    "    (\"http://www.ifremer.fr/erddap/griddap/SDC_GLO_CLIM_TS_V2_1\",\"Salinity\",\"salinity\"),\n",
    "    (\"http://www.ifremer.fr/erddap/griddap/SDC_GLO_CLIM_TS_V2_1\",\"Temperature\",\"temperature\"),\n",
    "    (\"https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/nitrate/all/1.00/woa18_all_n00_01.nc\",\"n_an\",\"nitrate\"),\n",
    "    (\"https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/silicate/all/1.00/woa18_all_i00_01.nc\",\"i_an\",\"silicate\"),\n",
    "    (\"https://www.ncei.noaa.gov/thredds-ocean/dodsC/ncei/woa/phosphate/all/1.00/woa18_all_p00_01.nc\",\"p_an\",\"phosphate\"),\n",
    "]\n",
    "\n",
    "DIVAndNN.prep_tempsalt(gridlon,gridlat,data_TS,datadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 0:3000\n",
    "ndimensions = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get bathymetry from GEBCO and prepare land-sea mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "bathname = joinpath(datadir,\"gebco_30sec_4.nc\");\n",
    "bathisglobal = true;\n",
    "maybedownload(\"https://dox.ulg.ac.be/index.php/s/RSwm4HPHImdZoQP/download\",\n",
    "              joinpath(datadir,\"gebco_30sec_4.nc\"))\n",
    "\n",
    "maskname = joinpath(datadir,\"mask.nc\");\n",
    "\n",
    "if !isfile(maskname)\n",
    "    DIVAndNN.prep_mask(bathname,bathisglobal,gridlon,gridlat,years,maskname)\n",
    "end\n",
    "\n",
    "ds = Dataset(maskname,\"r\")\n",
    "mask = nomissing(ds[\"mask\"][:,:]) .== 1\n",
    "close(ds)\n",
    "\n",
    "DIVAndNN.prep_bath(bathname,bathisglobal,gridlon,gridlat,datadir)\n",
    "\n",
    "if ndimensions == 3\n",
    "    mask = repeat(mask,inner=(1,1,length(years)))\n",
    "end\n",
    "\n",
    "if ndimensions == 3\n",
    "    mask2,pmn,xyi = DIVAnd.domain(bathname,bathisglobal,gridlon,gridlat,years);\n",
    "else\n",
    "    mask2,pmn,xyi = DIVAnd.domain(bathname,bathisglobal,gridlon,gridlat);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance to coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_fname = joinpath(datadir,\"dist2coast_subset.nc\")\n",
    "fname_dist2coast = \"https://pae-paha.pacioos.hawaii.edu/thredds/dodsC/dist2coast_1deg\"\n",
    "if !isfile(interp_fname)\n",
    "    DIVAndNN.prep_dist2coast(fname_dist2coast,gridlon,gridlat,interp_fname)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load covariables for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "covars_coord = false\n",
    "covars_const = true\n",
    "\n",
    "covars_fname = [\n",
    "    (\"bathymetry.nc\",       \"batymetry\",  identity),\n",
    "    (\"dist2coast_subset.nc\",\"distance\",   identity),\n",
    "    #(\"salinity.nc\",\"salinity\",log),\n",
    "    (\"salinity.nc\",         \"salinity\",   identity),\n",
    "    (\"temperature.nc\",      \"temperature\",identity),\n",
    "    (\"nitrate.nc\",          \"nitrate\",    identity),\n",
    "    (\"phosphate.nc\",        \"phosphate\",  identity),\n",
    "    (\"silicate.nc\",         \"silicate\",   identity),\n",
    "]\n",
    "\n",
    "covars_fname = map(entry -> (joinpath(datadir,entry[1]),entry[2:end]...),covars_fname)\n",
    "\n",
    "field = DIVAndNN.loadcovar((gridlon,gridlat),covars_fname;\n",
    "                           covars_coord = covars_coord,\n",
    "                           covars_const = covars_const)\n",
    "\n",
    "if ndimensions == 3\n",
    "    sz = size(field)\n",
    "    field = repeat(reshape(field,(sz[1],sz[2],1,sz[3])),1,1,length(years),1)\n",
    "end\n",
    "DIVAndNN.normalize!(mask,field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon, lat, dates, abundance, scientificNames = BlueCloudPlankton.read_data(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all unique scientific names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "scientificname_accepted = unique(scientificNames)\n",
    "@show unique(scientificNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly choose cross-validation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfname = replace(datafile,\".csv\" => \"-cv.nc\")\n",
    "validation_fraction = 0.2\n",
    "\n",
    "if isfile(cvfname)\n",
    "    @info \"load $cvfname\"\n",
    "\n",
    "    for_cv =\n",
    "        Dataset(cvfname,\"r\") do ds\n",
    "            Bool.(ds[\"for_cv\"][:])\n",
    "        end\n",
    "else\n",
    "    @info \"split data\"\n",
    "    for_cv = rand(length(lon)) .< validation_fraction\n",
    "\n",
    "    Dataset(cvfname,\"c\") do ds\n",
    "        defVar(ds,\"for_cv\",Int8.(for_cv),(\"observation\",),attrib = OrderedDict(\n",
    "            \"long_name\" => \"0: observation used for analysis; 1 observation used for validation\")\n",
    "               )\n",
    "    end\n",
    "end\n",
    "\n",
    "@show sum(for_cv)\n",
    "@show sum(.!for_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time correlation (for 3d analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lent = 0. # years\n",
    "if ndimensions == 3\n",
    "    lent = 5.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotevery = 100\n",
    "niter = 500\n",
    "trainfrac = 1.\n",
    "\n",
    "epsilon2ap = 10\n",
    "epsilon2_background = 10\n",
    "epsilon2_cpme = epsilon2_background\n",
    "\n",
    "NLayers = [size(field)[end],4,1]\n",
    "\n",
    "learning_rate = 0.001\n",
    "L2reg = 0.0001\n",
    "dropoutprob = 0.6\n",
    "\n",
    "len = 75e3\n",
    "len = 200e3\n",
    "len = 300e3\n",
    "\n",
    "# for len = [50e3, 75e3, 100e3, 125e3]\n",
    "#    for epsilon2ap = [1, 5, 10, 50, 100, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "        outdir = joinpath(resdir,\"results-ncovars$(length(covars_fname))-epsilon2ap$(epsilon2ap)-len$(len)-niter$(niter)-nlayers$(length(NLayers))-ndimensions$(ndimensions)\")\n",
    "        mkpath(outdir)\n",
    "\n",
    "        nameindex = 1\n",
    "        for nameindex in 1:length(scientificname_accepted)\n",
    "        #for nameindex in 1:1\n",
    "\n",
    "            sname = String(scientificname_accepted[nameindex])\n",
    "            global loss_iter\n",
    "            global val_iter\n",
    "            @info sname\n",
    "\n",
    "            paramname = joinpath(outdir,\"DIVAndNN_$(sname)_interp.json\")\n",
    "\n",
    "            if isfile(paramname)\n",
    "#                continue\n",
    "            end\n",
    "\n",
    "            s = (sname .== scientificNames) .& .!for_cv\n",
    "            lon_a,lat_a,obstime_a,value_a = lon[s], lat[s], dates[s], abundance[s]\n",
    "            @info \"number of observation used in analysis: $(sum(s))\"\n",
    "\n",
    "            s = (sname .== scientificNames) .& for_cv\n",
    "            lon_cv,lat_cv,obstime_cv,value_cv = lon[s], lat[s], dates[s], abundance[s]\n",
    "            @info \"number of observation used for validation: $(sum(s))\"\n",
    "\n",
    "            time_a = Float64.(Dates.year.(obstime_a))\n",
    "            time_cv = Float64.(Dates.year.(obstime_cv))\n",
    "\n",
    "            @show value_a[1:min(end,10)]\n",
    "            @show extrema(value_a)\n",
    "            @show length(value_a)\n",
    "\n",
    "            Random.seed!(1234)\n",
    "\n",
    "            value_analysis = zeros(size(mask))\n",
    "\n",
    "            if ndimensions == 3\n",
    "                xobs_a = (lon_a,lat_a,time_a)\n",
    "                xobs_cv = (lon_cv,lat_cv,time_cv)\n",
    "                lenxy = (len,len,lent)\n",
    "                analysis_grid = (gridlon,gridlat,years)\n",
    "            else\n",
    "                xobs_a = (lon_a,lat_a)\n",
    "                xobs_cv = (lon_cv,lat_cv)\n",
    "                lenxy = (len,len)\n",
    "                analysis_grid = (gridlon,gridlat)\n",
    "            end\n",
    "\n",
    "\n",
    "            loss_iter = []\n",
    "            val_iter = []\n",
    "\n",
    "            function plotres(i,lossi,value_analysis,y,gradloss,out,iobssel,obspos)\n",
    "                #@show extrema(value_analysis[isfinite.(value_analysis)])\n",
    "                vp = DIVAndNN.validate_regression(analysis_grid,value_analysis,xobs_cv,value_cv)\n",
    "                push!(loss_iter,lossi)\n",
    "                push!(val_iter,vp)\n",
    "\t            @printf(\"| %10d | %30.5f | %30.5f |\\n\",i,lossi,vp)\n",
    "            end\n",
    "\n",
    "            value_analysis,fw0 = DIVAndNN.analysisprob(\n",
    "                mask,pmn,xyi,xobs_a,\n",
    "                value_a,\n",
    "                lenxy,epsilon2ap,\n",
    "                field,\n",
    "                NLayers,\n",
    "                costfun = DIVAndNN.regression,\n",
    "                niter = niter,\n",
    "                dropoutprob = dropoutprob,\n",
    "                L2reg = L2reg,\n",
    "                learning_rate = learning_rate,\n",
    "\t            plotres = plotres,\n",
    "\t            plotevery = plotevery,\n",
    "                rmaverage = true,\n",
    "                trainfrac = trainfrac,\n",
    "                epsilon2_background = epsilon2_background,\n",
    "            )\n",
    "\n",
    "            vp = DIVAndNN.validate_regression(analysis_grid,value_analysis,xobs_cv,value_cv)\n",
    "            @show vp\n",
    "\n",
    "            outname = joinpath(outdir,\"DIVAndNN_$(sname)_interp.nc\")\n",
    "\n",
    "            cpme = DIVAnd_cpme(mask,pmn,xyi,xobs_a,value_a,lenxy,epsilon2_cpme)\n",
    "            DIVAnd.save(outname,(gridlon,gridlat),value_analysis,sname; relerr = cpme)\n",
    "\n",
    "            open(paramname,\"w\") do f\n",
    "                write(f,JSON.json(\n",
    "                    Dict(\n",
    "                        \"validation\" => vp,\n",
    "                        \"L2reg\" =>            L2reg,\n",
    "                        \"dropoutprob\" =>      dropoutprob,\n",
    "                        \"epsilon2ap\" =>       epsilon2ap,\n",
    "                        \"epsilon2_background\" => epsilon2_background,\n",
    "                        \"len\" =>              len,\n",
    "                        \"niter\" =>            niter,\n",
    "                        \"learning_rate\" =>    learning_rate,\n",
    "                        \"NLayers\" =>    NLayers,\n",
    "                        \"name\" =>    sname,\n",
    "                        \"loss_iter\" => loss_iter,\n",
    "                        \"val_iter\" => val_iter,\n",
    "                        \"covars\" => first.(covars_fname),\n",
    "                    )\n",
    "                ))\n",
    "            end\n",
    "\n",
    "        end\n",
    "\n",
    "        score = DIVAndNN.summary(outdir)\n",
    "\n",
    "        paramname2 = joinpath(outdir,\"DIVAndNN.json\")\n",
    "\n",
    "        open(paramname2,\"w\") do f\n",
    "            write(f,JSON.json(\n",
    "                Dict(\n",
    "                    \"validation\" => score,\n",
    "                    \"L2reg\" =>            L2reg,\n",
    "                    \"dropoutprob\" =>      dropoutprob,\n",
    "                    \"epsilon2ap\" =>       epsilon2ap,\n",
    "                    \"epsilon2_background\" => epsilon2_background,\n",
    "                    \"len\" =>              len,\n",
    "                    \"niter\" =>            niter,\n",
    "                    \"learning_rate\" =>    learning_rate,\n",
    "                    \"NLayers\" =>    NLayers,\n",
    "                    \"covars\" => first.(covars_fname),\n",
    "                )\n",
    "            ))\n",
    "        end\n",
    "#    end\n",
    "# end"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,jl:percent"
  },
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
